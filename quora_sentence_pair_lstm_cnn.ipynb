{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora_sentence_pair.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNpCmHJDune8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data\n",
        "import torchtext\n",
        "import spacy\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "\n",
        "\n",
        "path = '/content/drive/My Drive/'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAknfGLrwVRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', lower = True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "fields =[('question1',TEXT),('question2',TEXT),('is_duplicate',LABEL)]\n",
        "train_data,valid_data = data.TabularDataset.splits(\n",
        "        path=path, train='train_data_mod.csv', validation = 'validate_data_mod.csv',\n",
        "        format='csv',\n",
        "        skip_header = True,\n",
        "        fields=fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTTXZCA5z-Ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8617a791-c378-425f-f471-9d3aaa09788d"
      },
      "source": [
        "import torch\n",
        "\n",
        "MIN_FREQ = 2\n",
        "TEXT.build_vocab(train_data, \n",
        "                 min_freq = MIN_FREQ,\n",
        "                 vectors = \"glove.6B.300d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.23MB/s]                           \n",
            "100%|█████████▉| 399129/400000 [00:40<00:00, 10161.35it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5lehs9N0bPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "175532cb-8f4d-42a9-81cc-d32ce7eeef95"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 54531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ueKnEly3_Za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77329cce-8798-4900-d503-6db8a98fa669"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('?', 830871), ('the', 368146), ('what', 316488), ('is', 264383), ('i', 217268), ('how', 215290), ('a', 206069), ('to', 200540), ('in', 191971), ('do', 165563), ('of', 155911), ('are', 143078), ('and', 129948), ('can', 111803), ('for', 101851), (',', 95847), ('you', 90885), ('why', 82028), ('it', 69280), ('my', 69196)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJaqwfv54GTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f686fbf-194b-441f-bbb9-828b6ed6a968"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '?', 'the', 'what', 'is', 'i', 'how', 'a', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo5RaHcz4M6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc64aaf8-5d4c-414a-dd7a-fdce9579c2d5"
      },
      "source": [
        "print(LABEL.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX48PbiE4QiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee46c4dd-f896-429f-ecd9-f0de1ee79462"
      },
      "source": [
        "print(LABEL.vocab.freqs.most_common())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('0', 248442), ('1', 145848)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOQilVTe4YD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39de94e9-23e2-46d1-d870-30491ac8ffd5"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device')\n",
        "\n",
        "train_iterator = data.BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "\n",
        "valid_iterator = data.BucketIterator(\n",
        "    valid_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39DPWkP6UTaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #maxpool\n",
        "# class NLIBiLSTM(nn.Module):\n",
        "#     def __init__(self, \n",
        "#                  input_dim, \n",
        "#                  embedding_dim,\n",
        "#                  hidden_dim,\n",
        "#                  n_lstm_layers,\n",
        "#                  n_fc_layers,\n",
        "#                  output_dim, \n",
        "#                  dropout, \n",
        "#                  pad_idx):\n",
        "        \n",
        "#         super().__init__()\n",
        "                                \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "#         self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "#         self.lstm = nn.LSTM(hidden_dim, \n",
        "#                             hidden_dim, \n",
        "#                             num_layers = n_lstm_layers, \n",
        "#                             bidirectional = True, \n",
        "#                             dropout=dropout if n_lstm_layers > 1 else 0)\n",
        "        \n",
        "#         fc_dim = hidden_dim * 2\n",
        "        \n",
        "#         fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "#         self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "#         self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "#     def forward(self, prem, hypo):\n",
        "\n",
        "#         prem_seq_len, batch_size = prem.shape\n",
        "#         hypo_seq_len, _ = hypo.shape\n",
        "        \n",
        "       \n",
        "        \n",
        "#         embedded_prem = self.embedding(prem)\n",
        "#         embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "        \n",
        "#         translated_prem = F.relu(self.translation(embedded_prem))\n",
        "#         translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "        \n",
        "        \n",
        "        \n",
        "#         outputs_prem, (hidden_prem, cell_prem) = self.lstm(translated_prem)\n",
        "#         outputs_hypo, (hidden_hypo, cell_hypo) = self.lstm(translated_hypo)\n",
        "\n",
        "       \n",
        "#         outputs_prem = torch.max(outputs_prem,0)[0]\n",
        "#         outputs_hypo = torch.max(outputs_hypo,0)[0] \n",
        "\n",
        "#         hidden = torch.cat((outputs_prem, outputs_hypo,torch.abs(outputs_prem-outputs_hypo),outputs_prem*outputs_hypo), dim=1)\n",
        "\n",
        "\n",
        "#         #hidden = [batch size, fc dim * 2]\n",
        "#         for fc in self.fcs:\n",
        "#             hidden = fc(hidden)\n",
        "#             hidden = F.relu(hidden)\n",
        "#             hidden = self.dropout(hidden)\n",
        "        \n",
        "#         prediction = self.fc_out(hidden)\n",
        "        \n",
        "#         #prediction = [batch size, output dim]\n",
        "        \n",
        "#         return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ebmMmVffFit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # will do mean pool\n",
        "# class NLIBiLSTM(nn.Module):\n",
        "#     def __init__(self, \n",
        "#                  input_dim, \n",
        "#                  embedding_dim,\n",
        "#                  hidden_dim,\n",
        "#                  n_lstm_layers,\n",
        "#                  n_fc_layers,\n",
        "#                  output_dim, \n",
        "#                  dropout, \n",
        "#                  pad_idx):\n",
        "        \n",
        "#         super().__init__()\n",
        "                                \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "#         self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "#         self.lstm = nn.LSTM(hidden_dim, \n",
        "#                             hidden_dim, \n",
        "#                             num_layers = n_lstm_layers, \n",
        "#                             bidirectional = True, \n",
        "#                             dropout=dropout if n_lstm_layers > 1 else 0)\n",
        "        \n",
        "#         fc_dim = hidden_dim * 2\n",
        "        \n",
        "#         fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "#         self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "#         self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "#     def forward(self, prem, hypo):\n",
        "\n",
        "#         prem_seq_len, batch_size = prem.shape\n",
        "#         hypo_seq_len, _ = hypo.shape\n",
        "        \n",
        "#         embedded_prem = self.embedding(prem)\n",
        "#         embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "#         translated_prem = F.relu(self.translation(embedded_prem))\n",
        "#         translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "        \n",
        "#         outputs_prem, (hidden_prem, cell_prem) = self.lstm(translated_prem)\n",
        "#         outputs_hypo, (hidden_hypo, cell_hypo) = self.lstm(translated_hypo)\n",
        "\n",
        "#         outputs_prem = torch.mean(outputs_prem,0)\n",
        "#         outputs_hypo = torch.mean(outputs_hypo,0) \n",
        "\n",
        "#         hidden = torch.cat((outputs_prem, outputs_hypo,torch.abs(outputs_prem-outputs_hypo),outputs_prem*outputs_hypo), dim=1)\n",
        "\n",
        "\n",
        "#         #hidden = [batch size, fc dim * 2]\n",
        "#         for fc in self.fcs:\n",
        "#             hidden = fc(hidden)\n",
        "#             hidden = F.relu(hidden)\n",
        "#             hidden = self.dropout(hidden)\n",
        "        \n",
        "#         prediction = self.fc_out(hidden)\n",
        "        \n",
        "#         #prediction = [batch size, output dim]\n",
        "        \n",
        "#         return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQTxG2IEfJVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # will do no pooling\n",
        "# class NLIBiLSTM(nn.Module):\n",
        "#     def __init__(self, \n",
        "#                  input_dim, \n",
        "#                  embedding_dim,\n",
        "#                  hidden_dim,\n",
        "#                  n_lstm_layers,\n",
        "#                  n_fc_layers,\n",
        "#                  output_dim, \n",
        "#                  dropout, \n",
        "#                  pad_idx):\n",
        "        \n",
        "#         super().__init__()\n",
        "                                \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "#         self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "#         self.lstm = nn.LSTM(hidden_dim, \n",
        "#                             hidden_dim, \n",
        "#                             num_layers = n_lstm_layers, \n",
        "#                             bidirectional = True, \n",
        "#                             dropout=dropout if n_lstm_layers > 1 else 0)\n",
        "        \n",
        "#         fc_dim = hidden_dim * 2\n",
        "        \n",
        "#         fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "#         self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "#         self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "#     def forward(self, prem, hypo):\n",
        "\n",
        "#         prem_seq_len, batch_size = prem.shape\n",
        "#         hypo_seq_len, _ = hypo.shape\n",
        "        \n",
        "#         embedded_prem = self.embedding(prem)\n",
        "#         embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "#         translated_prem = F.relu(self.translation(embedded_prem))\n",
        "#         translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "        \n",
        "#         outputs_prem, (hidden_prem, cell_prem) = self.lstm(translated_prem)\n",
        "#         outputs_hypo, (hidden_hypo, cell_hypo) = self.lstm(translated_hypo)\n",
        "        \n",
        "#         hidden_prem = torch.cat((hidden_prem[-1], hidden_prem[-2]), dim=-1)\n",
        "#         hidden_hypo = torch.cat((hidden_hypo[-1], hidden_hypo[-2]), dim=-1)\n",
        "       \n",
        "       \n",
        "#         hidden = torch.cat((hidden_prem, hidden_hypo,torch.abs(hidden_prem-hidden_hypo),hidden_prem*hidden_hypo), dim=1)\n",
        "\n",
        "#         for fc in self.fcs:\n",
        "#             hidden = fc(hidden)\n",
        "#             hidden = F.relu(hidden)\n",
        "#             hidden = self.dropout(hidden)\n",
        "        \n",
        "#         prediction = self.fc_out(hidden)\n",
        "        \n",
        "#         return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0Kf0J1fWfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #attention model\n",
        "# class NLIBiLSTM(nn.Module):\n",
        "#     def __init__(self, \n",
        "#                  input_dim, \n",
        "#                  embedding_dim,\n",
        "#                  hidden_dim,\n",
        "#                  n_lstm_layers,\n",
        "#                  n_fc_layers,\n",
        "#                  output_dim, \n",
        "#                  dropout, \n",
        "#                  pad_idx):\n",
        "        \n",
        "#         super().__init__()\n",
        "                                \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "#         self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "#         self.lstm = nn.LSTM(hidden_dim, \n",
        "#                             hidden_dim, \n",
        "#                             num_layers = n_lstm_layers, \n",
        "#                             bidirectional = True, \n",
        "#                             dropout=dropout if n_lstm_layers > 1 else 0)\n",
        "        \n",
        "#         fc_dim = hidden_dim * 2\n",
        "\n",
        "#         self.ws1 = torch.nn.Parameter(torch.zeros(2*hidden_dim,2*hidden_dim),requires_grad=True)\n",
        "#         self.ws2 = torch.nn.Parameter(torch.zeros(2*hidden_dim,1),requires_grad=True)\n",
        "\n",
        "#         self.tanh = nn.Tanh()\n",
        "#         self.softmax = nn.Softmax(dim = 1)\n",
        "\n",
        "#         torch.nn.init.xavier_uniform_(self.ws1.data)\n",
        "#         torch.nn.init.xavier_uniform_(self.ws2.data)\n",
        "\n",
        "\n",
        "        \n",
        "#         fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "#         self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "#         self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "#     def forward(self, prem, hypo):\n",
        "\n",
        "#         prem_seq_len, batch_size = prem.shape\n",
        "#         hypo_seq_len, _ = hypo.shape\n",
        "          \n",
        "#         embedded_prem = self.embedding(prem)\n",
        "#         embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "        \n",
        "#         translated_prem = F.relu(self.translation(embedded_prem))\n",
        "#         translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "        \n",
        "#         outputs_prem, (hidden_prem, cell_prem) = self.lstm(translated_prem)\n",
        "#         outputs_hypo, (hidden_hypo, cell_hypo) = self.lstm(translated_hypo)\n",
        "#         outputs_prem = outputs_prem.permute(1,0,2)\n",
        "#         outputs_hypo = outputs_hypo.permute(1,0,2)\n",
        "\n",
        "\n",
        "#         batch_size = outputs_prem.shape[0]\n",
        "\n",
        "#         x = torch.bmm(outputs_prem,self.ws1.repeat(batch_size,1,1))\n",
        "#         x = self.tanh(x)\n",
        "#         x = torch.bmm(x,self.ws2.repeat(batch_size,1,1))\n",
        "#         x = self.softmax(x)\n",
        "#         x  = outputs_prem * x\n",
        "#         x_prem = torch.sum(x,dim =1).squeeze()\n",
        "\n",
        "#         x = torch.bmm(outputs_hypo,self.ws1.repeat(batch_size,1,1))\n",
        "#         x = self.tanh(x)\n",
        "#         x = torch.bmm(x,self.ws2.repeat(batch_size,1,1))\n",
        "#         x = self.softmax(x)\n",
        "#         x  = outputs_hypo * x\n",
        "#         x_hypo = torch.sum(x,dim=1).squeeze()\n",
        "       \n",
        "\n",
        "#         hidden = torch.cat((x_prem, x_hypo,torch.abs(x_prem-x_hypo),x_prem*x_hypo), dim=1)\n",
        "\n",
        "\n",
        "        \n",
        "#         for fc in self.fcs:\n",
        "#             hidden = fc(hidden)\n",
        "#             hidden = F.relu(hidden)\n",
        "#             hidden = self.dropout(hidden)\n",
        "        \n",
        "#         prediction = self.fc_out(hidden)  \n",
        "#         return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_lF2f3r5C8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1D CNN\n",
        "class NLIBiLSTM(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 n_lstm_layers,\n",
        "                 n_fc_layers,\n",
        "                 output_dim, \n",
        "                 dropout, \n",
        "                 pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "                                \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "        window_size = 3;\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1,1,(window_size,1))\n",
        "        self.conv2 = nn.Conv2d(1,1,(window_size,1))\n",
        "        self.conv3 = nn.Conv2d(1,1,(window_size,1))\n",
        "        self.conv4 = nn.Conv2d(1,1,(window_size,1))\n",
        "\n",
        "        fc_dim = hidden_dim\n",
        "\n",
        "                \n",
        "        fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "        self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "        self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "    def forward(self, prem, hypo):\n",
        "\n",
        "        prem_seq_len, batch_size = prem.shape\n",
        "        hypo_seq_len, _ = hypo.shape\n",
        "          \n",
        "        embedded_prem = self.embedding(prem)\n",
        "        embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "        \n",
        "        translated_prem = F.relu(self.translation(embedded_prem))\n",
        "        translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "\n",
        "        translated_prem = translated_prem.reshape(1,translated_prem.shape[0],translated_prem.shape[1],-1).permute(2,0,1,3)\n",
        "        translated_hypo = translated_hypo.reshape(1,translated_hypo.shape[0],translated_hypo.shape[1],-1).permute(2,0,1,3)\n",
        "\n",
        "        # print(translated_prem.shape)\n",
        "        # print(translated_hypo.shape)\n",
        "\n",
        "\n",
        "        x = (self.conv1(translated_prem))\n",
        "        x = (self.conv2(x))\n",
        "        x = (self.conv3(x))\n",
        "        x = (self.conv4(x))\n",
        "        x = x.squeeze()\n",
        "        x = torch.max(x,1)[0]\n",
        "\n",
        "        y = (self.conv1(translated_hypo))\n",
        "        y = (self.conv2(y))\n",
        "        y = (self.conv3(y))\n",
        "        y = (self.conv4(y))\n",
        "        y = y.squeeze()\n",
        "        y = torch.max(y,1)[0]\n",
        "\n",
        "        # print(x.shape)\n",
        "        # print(y.shape)\n",
        "        # sys.exit()\n",
        "\n",
        "\n",
        "        hidden = torch.cat((x,y,torch.abs(x-y),x*y), dim=1)\n",
        "\n",
        "\n",
        "        \n",
        "        for fc in self.fcs:\n",
        "            hidden = fc(hidden)\n",
        "            hidden = F.relu(hidden)\n",
        "            hidden = self.dropout(hidden)\n",
        "        \n",
        "        prediction = self.fc_out(hidden)  \n",
        "        return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcTR_dsBb6Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 1D CNN\n",
        "# class NLIBiLSTM(nn.Module):\n",
        "#     def __init__(self, \n",
        "#                  input_dim, \n",
        "#                  embedding_dim,\n",
        "#                  hidden_dim,\n",
        "#                  n_lstm_layers,\n",
        "#                  n_fc_layers,\n",
        "#                  output_dim, \n",
        "#                  dropout, \n",
        "#                  pad_idx):\n",
        "        \n",
        "#         super().__init__()\n",
        "                                \n",
        "#         self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "#         self.translation = nn.Linear(embedding_dim, hidden_dim)\n",
        "#         window_size = 3;\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(1,300,(window_size,300))\n",
        "#         self.conv2 = nn.Conv2d(1,300,(window_size,300))\n",
        "#         self.conv3 = nn.Conv2d(1,300,(window_size,300))\n",
        "#         self.conv4 = nn.Conv2d(1,300,(window_size,300))\n",
        "\n",
        "#         fc_dim = hidden_dim\n",
        "\n",
        "                \n",
        "#         fcs = [nn.Linear(fc_dim * 4, fc_dim * 4) for _ in range(n_fc_layers)]\n",
        "        \n",
        "#         self.fcs = nn.ModuleList(fcs)\n",
        "        \n",
        "#         self.fc_out = nn.Linear(fc_dim * 4, output_dim)\n",
        "        \n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "           \n",
        "#     def forward(self, prem, hypo):\n",
        "\n",
        "#         prem_seq_len, batch_size = prem.shape\n",
        "#         hypo_seq_len, _ = hypo.shape\n",
        "          \n",
        "#         embedded_prem = self.embedding(prem)\n",
        "#         embedded_hypo = self.embedding(hypo)\n",
        "        \n",
        "        \n",
        "#         translated_prem = F.relu(self.translation(embedded_prem))\n",
        "#         translated_hypo = F.relu(self.translation(embedded_hypo))\n",
        "\n",
        "#         translated_prem = translated_prem.reshape(1,translated_prem.shape[0],translated_prem.shape[1],-1).permute(2,0,1,3)\n",
        "#         translated_hypo = translated_hypo.reshape(1,translated_hypo.shape[0],translated_hypo.shape[1],-1).permute(2,0,1,3)\n",
        "\n",
        "#         # print(translated_prem.shape)\n",
        "#         # print(translated_hypo.shape)\n",
        "\n",
        "\n",
        "#         x = F.relu(self.conv1(translated_prem).permute(0,3,2,1))\n",
        "#         x = F.relu(self.conv2(x).permute(0,3,2,1))\n",
        "#         x = F.relu(self.conv3(x).permute(0,3,2,1))\n",
        "#         x = F.relu(self.conv4(x).permute(0,3,2,1))\n",
        "#         x = x.squeeze()\n",
        "#         x = torch.max(x,1)[0]\n",
        "\n",
        "#         y = F.relu(self.conv1(translated_hypo).permute(0,3,2,1))\n",
        "#         y = F.relu(self.conv2(y).permute(0,3,2,1))\n",
        "#         y = F.relu(self.conv3(y).permute(0,3,2,1))\n",
        "\n",
        "#         y = F.relu(self.conv4(y).permute(0,3,2,1))\n",
        "#         y = y.squeeze()\n",
        "#         y = torch.max(y,1)[0]\n",
        "\n",
        "#         # print(x.shape)\n",
        "#         # print(y.shape)\n",
        "#         # sys.exit()\n",
        "\n",
        "\n",
        "#         hidden = torch.cat((x,y,torch.abs(x-y),x*y), dim=1)\n",
        "\n",
        "\n",
        "        \n",
        "#         for fc in self.fcs:\n",
        "#             hidden = fc(hidden)\n",
        "#             hidden = F.relu(hidden)\n",
        "#             hidden = self.dropout(hidden)\n",
        "        \n",
        "#         prediction = self.fc_out(hidden)  \n",
        "#         return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcDqFVKdUe4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 300\n",
        "N_LSTM_LAYERS = 1\n",
        "N_FC_LAYERS = 3\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = NLIBiLSTM(INPUT_DIM,\n",
        "                  EMBEDDING_DIM,\n",
        "                  HIDDEN_DIM,\n",
        "                  N_LSTM_LAYERS,\n",
        "                  N_FC_LAYERS,\n",
        "                  OUTPUT_DIM,\n",
        "                  DROPOUT,\n",
        "                  PAD_IDX).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6HVN66TUye5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f00eeda0-22f1-4481-f156-79b12322fdd5"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 20,775,618 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqvNui40U5S3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9cd13ab-8854-4783-86f7-559ddcb1186c"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([54531, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weXhUfXYVFjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "cfe072fe-c612-4e95-8dac-c23d646193a8"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8543,  0.8804,  1.4771,  ..., -3.3385,  3.2162,  0.8564],\n",
              "        [ 1.1484, -0.9949,  0.2790,  ...,  0.1340,  0.3709, -1.4518],\n",
              "        [-0.0833, -0.2090, -0.0436,  ..., -0.1775,  0.0558,  0.8013],\n",
              "        ...,\n",
              "        [ 0.9971, -1.9249,  0.2666,  ...,  0.1870,  0.8133, -0.5361],\n",
              "        [-1.2981, -0.2590, -0.1845,  ...,  0.6690, -1.3790, -0.0625],\n",
              "        [ 0.6180,  0.5993, -0.6279,  ..., -1.3815, -0.8079,  0.0175]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBJeNXSHVJey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "021dd4c5-8625-4ca6-fe73-b9fa296fb8f9"
      },
      "source": [
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8543,  0.8804,  1.4771,  ..., -3.3385,  3.2162,  0.8564],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0833, -0.2090, -0.0436,  ..., -0.1775,  0.0558,  0.8013],\n",
            "        ...,\n",
            "        [ 0.9971, -1.9249,  0.2666,  ...,  0.1870,  0.8133, -0.5361],\n",
            "        [-1.2981, -0.2590, -0.1845,  ...,  0.6690, -1.3790, -0.0625],\n",
            "        [ 0.6180,  0.5993, -0.6279,  ..., -1.3815, -0.8079,  0.0175]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGhMBoXoVMot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.embedding.weight.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG47B4-wVPkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e21666a4-4d5b-490a-a308-3fc8e0d26564"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,416,318 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_14VutJBVSgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTlLbBeWVX3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvsfwUeEVfkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldBTR0O7Vir0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        prem = batch.question1\n",
        "        hypo = batch.question2\n",
        "        labels = batch.is_duplicate\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "       \n",
        "        predictions = model(prem, hypo)\n",
        "        \n",
        "        loss = criterion(predictions, labels)\n",
        "                \n",
        "        acc = categorical_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO1_xd1tVmPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for batch in iterator:\n",
        "        prem = batch.question1\n",
        "        hypo = batch.question2\n",
        "        labels = batch.is_duplicate\n",
        "        predictions = model(prem, hypo)\n",
        "            \n",
        "        loss = criterion(predictions, labels)\n",
        "                \n",
        "        acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaAd9429VqO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "loss_1 = []\n",
        "loss_2 = []\n",
        "acc_1 = []\n",
        "acc_2 = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVbWuQEDVs8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "83ad424e-78ec-4d5c-8385-c36423b946a9"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'deep_model.pt')\n",
        "    loss_1.append(train_loss)\n",
        "    loss_2.append(valid_loss)\n",
        "    acc_1.append(train_acc)\n",
        "    acc_2.append(valid_acc)\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.458 | Train Acc: 77.13%\n",
            "\t Val. Loss: 0.390 |  Val. Acc: 81.71%\n",
            "Epoch: 02 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.365 | Train Acc: 83.01%\n",
            "\t Val. Loss: 0.358 |  Val. Acc: 83.64%\n",
            "Epoch: 03 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.331 | Train Acc: 84.83%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 84.64%\n",
            "Epoch: 04 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 0.306 | Train Acc: 86.15%\n",
            "\t Val. Loss: 0.341 |  Val. Acc: 84.74%\n",
            "Epoch: 05 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.287 | Train Acc: 87.19%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 84.75%\n",
            "Epoch: 06 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.271 | Train Acc: 87.97%\n",
            "\t Val. Loss: 0.325 |  Val. Acc: 85.31%\n",
            "Epoch: 07 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.255 | Train Acc: 88.76%\n",
            "\t Val. Loss: 0.338 |  Val. Acc: 85.44%\n",
            "Epoch: 08 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 0.242 | Train Acc: 89.41%\n",
            "\t Val. Loss: 0.332 |  Val. Acc: 85.77%\n",
            "Epoch: 09 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.229 | Train Acc: 90.10%\n",
            "\t Val. Loss: 0.364 |  Val. Acc: 85.52%\n",
            "Epoch: 10 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 0.217 | Train Acc: 90.60%\n",
            "\t Val. Loss: 0.349 |  Val. Acc: 85.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGuRo3ulSWMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1c02f1db-284d-4904-b296-fd0702ab9403"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_1,label = 'training_loss')\n",
        "plt.plot(loss_2,label = 'validation_loss')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4a4df0ee48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iat8ifJbSicm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7b59e0de-65b9-44c4-de65-14a161bcccc7"
      },
      "source": [
        "plt.plot(acc_1,label = 'training_acc')\n",
        "plt.plot(acc_2,label = 'validation_acc')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4a4e176860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T5rEPqPxHbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}